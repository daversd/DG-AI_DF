{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pix2Pix Training \n",
    "Implementation based on https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "Developed by David DÃ³ria https://github.com/daversd for\n",
    "2021-2022 B-pro Architectural Design RC4\n",
    "\n",
    "Pix2Pix is a conditional genrative adversarial network model that performs image-to-image translations, learning how to do this operation from a data set of image pairs (input and expected outputs). This implementation uses `256x256 px` images for input and output, expecting training set to be formatted already in a folder that contains `/AB/train/` and `AB/test/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pix2pix_helpers.util as util\n",
    "from pix2pix_helpers.create_dataset import ImageFolderLoader\n",
    "from pix2pix_helpers.pix2pix_model import Pix2PixModel\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level setup\n",
    "Important notes:\n",
    "- Use a training set that is at least on the hundreds figure to have a realiable result. The more, the better\n",
    "- If you are doing multiple instances of training, and you would like to keep track of the different results of each instance of training, remember to update the value of `MODEL_NAME`. Otherwise, the data produced previously will be overwritten.\n",
    "- 300 epochs is a good number. If you use more epochs, ensure you keep track of the training outputs to check if your model is not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False             # Determines if the program must enter training mode\n",
    "TEST = False             # Determines if the program must enter testing mode (loads the latest checkpoint)\n",
    "TEST_SAMPLE = 10         # The number of samples for testing mode\n",
    "WRITE_LOGS = True       # Determines if tensorboard logs should be written to disk\n",
    "SAVE_CKPTS = True       # Determines if checkpoints should be saved\n",
    "SAVE_IMG_CKPT = True    # Determines if images should be saved for each checkpoint\n",
    "EXPORT_MODEL = True     # Determines if the model should be exported (loads the latest checkpoint)\n",
    "\n",
    "FOLDER_NAME = 'data/tracos'                            # The name of the data folder\n",
    "MODEL_NAME = 'tracos_run_1'                            # The name of the model for this run\n",
    "LOAD_NUMBER = -1                                        # Number of the model to be loaded (-1 loads the latest)\n",
    "CKPT_DIR = os.path.join('checkpoints', MODEL_NAME)      # The folder to save checkpoints to\n",
    "LOG_DIR = 'runs/' + MODEL_NAME                          # The folder to save tensorboard logs to\n",
    "TEST_DIR = 'test/' + MODEL_NAME                         # The folder to save test images to\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 100                # Will be split in two parts, must be even\n",
    "\n",
    "PRINT_FREQ = 100            # Interval of steps between print logs\n",
    "LOG_FREQ = 100              # Interval of steps between tensorboard logs\n",
    "CKPT_FREQ = 10              # Interval of epochs between checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish setup and create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the required folders\n",
    "if SAVE_CKPTS:\n",
    "    if not os.path.isdir(CKPT_DIR):\n",
    "        os.makedirs(CKPT_DIR)\n",
    "\n",
    "if WRITE_LOGS:\n",
    "    if not os.path.isdir(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "\n",
    "if SAVE_IMG_CKPT:\n",
    "    if not os.path.isdir(TEST_DIR):\n",
    "        os.makedirs(TEST_DIR)\n",
    "\n",
    "# Initialize the log writer\n",
    "if WRITE_LOGS:\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to load saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    \"\"\"\n",
    "    Loads the networks from the checkpoint specified in LOAD_NUMBER\n",
    "    Use -1 to load the latest model.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_files = glob.glob(CKPT_DIR + '/*.pth')\n",
    "\n",
    "    if LOAD_NUMBER == -1:\n",
    "        file_path = max(list_of_files, key=os.path.getctime)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_number = file_name.split('_')[0]\n",
    "        print(file_number)\n",
    "    else:\n",
    "        file_number = LOAD_NUMBER\n",
    "    \n",
    "    file_prefix = os.path.join(CKPT_DIR, str(file_number) + '_')\n",
    "    netG_File = file_prefix + 'net_G.pth'\n",
    "    netD_File = file_prefix + 'net_D.pth'\n",
    "    \n",
    "    files_exist = os.path.exists(netG_File) and os.path.exists(netD_File)\n",
    "    assert files_exist, f\"Checkpoint {LOAD_NUMBER} does not exist. Check '{CKPT_DIR}' to see available checkpoints\"\n",
    "    print(f\"Loading model from checkpoint {file_number} \\n\"+ f\"Generator is {netG_File} \\n\" + f\"Discriminator is {netD_File}\")\n",
    "\n",
    "    model.load_networks(file_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program\n",
    "Train the discriminator and generator for `EPOCHS` using the training data that is present on `FOLDER_NAME`. Checkpoints are saved to `CKPT_DIR`, training status is printed to the console and saved to the writer (if defined so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    # Create the training data set\n",
    "    trainData = ImageFolderLoader(\n",
    "        f\"{FOLDER_NAME}/AB\", phase='train', preprocess='none')\n",
    "    trainSet = torch.utils.data.DataLoader(\n",
    "        trainData, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Create the pix2pix model\n",
    "    model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=True,\n",
    "                         n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "\n",
    "    model.setup()\n",
    "    total_iters = 0\n",
    "\n",
    "    # Initiate the training iteration\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "\n",
    "        if epoch != 0:\n",
    "            model.update_learning_rate()\n",
    "\n",
    "        # Iterate through the data batches in the training set\n",
    "        for i, data in enumerate(trainSet):\n",
    "            iter_start_time = time.time()\n",
    "\n",
    "            # Setup counters\n",
    "            total_iters += BATCH_SIZE\n",
    "            epoch_iter += BATCH_SIZE\n",
    "\n",
    "            # Feed input through model, optimize parameters\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            # Use this for logging losses in tensorboard\n",
    "            if total_iters % PRINT_FREQ == 0:\n",
    "                losses = model.get_current_losses()\n",
    "                t_comp = (time.time() - iter_start_time) / BATCH_SIZE\n",
    "                print(\n",
    "                    f'Step {total_iters} | Epoch {epoch} | GAN Loss: {losses[\"G_GAN\"]:.3f} | Gen. L1: {losses[\"G_L1\"]:.3f} | Disc. real: {losses[\"D_real\"]:.3f} | Disc. fake: {losses[\"D_fake\"]:.3f}')\n",
    "\n",
    "            # Use this to log to tensorboard\n",
    "            if WRITE_LOGS and total_iters % LOG_FREQ == 0:\n",
    "                losses = model.get_current_losses().items()\n",
    "                for name, loss in losses:\n",
    "                    writer.add_scalar(name, loss, total_iters)  # type: ignore\n",
    "                writer.close()  # type: ignore\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "\n",
    "        # Save checkpoints per epochs\n",
    "        if SAVE_CKPTS and epoch % CKPT_FREQ == 0:\n",
    "            print('Saving the model at the end of epoch %d, iters %d' %\n",
    "                  (epoch, total_iters))\n",
    "            model.save_network(epoch)\n",
    "\n",
    "            # Save image per checkpoint\n",
    "            if SAVE_IMG_CKPT:\n",
    "                print('Saving current epoch test to test folder')\n",
    "                visuals = model.get_current_visuals()\n",
    "                save_path = os.path.join(\n",
    "                    TEST_DIR, 'epoch_' + str(epoch) + '.jpg')\n",
    "                util.save_visuals(visuals, save_path)\n",
    "\n",
    "        # Print details at the end of the epoch\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d secs' %\n",
    "              (epoch, EPOCHS -1, time.time() - epoch_start_time))\n",
    "\n",
    "    # Save / overwrite final epoch and image\n",
    "    if SAVE_CKPTS:\n",
    "        print('Saving the model at the end of training')\n",
    "        model.save_network(epoch)\n",
    "\n",
    "        if SAVE_IMG_CKPT:\n",
    "            print('Saving final epoch test to test folder')\n",
    "            visuals = model.get_current_visuals()\n",
    "            save_path = os.path.join(TEST_DIR, 'epoch_' + str(epoch) + '.jpg')\n",
    "            util.save_visuals(visuals, save_path)\n",
    "\n",
    "    # Plot last visuals from the model once training is complete\n",
    "    visuals = model.get_current_visuals()\n",
    "    util.plot_visuals(visuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "Generate a batch of images, defined by `TEST_SAMPLE`, using the images that are on its `test` folder. It loads the model from the checkpoint defined by `LOAD_NUMBER`. The generated images are saved to `TEST_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "        # Create the testing data set\n",
    "        testData = ImageFolderLoader(f'{FOLDER_NAME}/AB', phase='test', flip=False, preprocess='none')\n",
    "        testSet = torch.utils.data.DataLoader(testData, batch_size=BATCH_SIZE, shuffle= False, num_workers=0)\n",
    "\n",
    "        # Create the pix2pix model in testing mode\n",
    "        model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=False, n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "        model.setup()\n",
    "        model.eval()\n",
    "        load_model(model)\n",
    "\n",
    "        # Iterate through test data set, for the lenght of the test sample\n",
    "        for i, data in enumerate(testSet):\n",
    "            if i < TEST_SAMPLE:\n",
    "                model.set_input(data)\n",
    "                model.test()\n",
    "                visuals = model.get_current_visuals()\n",
    "                save_path = os.path.join(TEST_DIR, 'test_' + str(i) + '.jpg')\n",
    "                util.save_visuals(visuals, save_path)\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Model\n",
    "In order to use the model outside this training setup, you need to export it. An exported model in the `.onnx` format can be used by Unity using its `Barracuda` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "Loading model from checkpoint 100 \n",
      "Generator is checkpoints\\tracos_run_1\\100_net_G.pth \n",
      "Discriminator is checkpoints\\tracos_run_1\\100_net_D.pth\n",
      "Loading the model from checkpoints\\tracos_run_1\\100_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "if EXPORT_MODEL:\n",
    "        # Create dummy input\n",
    "        x = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "        # Create the model and load the latest checkpoint\n",
    "        model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=False, n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "        model.setup()\n",
    "        model.eval()\n",
    "        load_model(model)\n",
    "\n",
    "        if not os.path.isdir('exported'):\n",
    "            os.makedirs('exported')\n",
    "        \n",
    "        path = os.path.join('exported', f'{MODEL_NAME}.onnx')\n",
    "        f = open(path, 'w+')\n",
    "\n",
    "        torch.onnx.export(model.netG, x.to(DEVICE), path, training=torch.onnx.TrainingMode.EVAL, export_params=True, opset_version=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e71fdd7c552fe95a1eacb854f1b10e9ecb90034276b5430645f7c41b103f00ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch-ready')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
